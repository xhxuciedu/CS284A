{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dim-reduction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMoVNIxa9mYv9zV/H/C+bnE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xhxuciedu/CS284A/blob/master/dim-reduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrWzjGZCJ4PV"
      },
      "source": [
        "## Dimension reduction \n",
        "three Dimensionality reduction techniques specifically used for Data Visualization: PCA, t-SNE, LDA and UMAP. We are going to explore them in details using the Sign Language MNIST Dataset, without going in-depth with the maths behind the algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jT6FFNEHMfl"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# For plotting\n",
        "import plotly.io as plt_io\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "#PCA\n",
        "from sklearn.decomposition import PCA\n",
        "#TSNE\n",
        "from sklearn.manifold import TSNE\n",
        "#UMAP\n",
        "import umap\n",
        "#LDA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMPKHFM9KI2e"
      },
      "source": [
        "Main Approaches for Dimensionality Reduction\n",
        "\n",
        "The two main approaches to reducing dimensionality: Projection and Manifold Learning.\n",
        "\n",
        "* Projection: This technique deals with projecting every data point which is in high dimension, onto a subspace suitable lower-dimensional space in a way which approximately preserves the distances between the points.\n",
        "* Manifold Learning: Many dimensionality reductions algorithm work by modelling the manifold on which the training instance lie; this is called Manifold learning. It relies on the manifold hypothesis or assumption, which holds that most real-world high-dimensional datasets lie close to a much lower-dimensional manifold, this assumption in most of the cases is based on observation or experience rather than theory or pure logic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on5xdyCVJOfq"
      },
      "source": [
        "## Dataset\n",
        "Download from\n",
        "https://www.kaggle.com/datamunge/sign-language-mnist\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-YlZePEHUAo"
      },
      "source": [
        "train = pd.read_csv('/kaggle/input/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv')\n",
        "train.head()\n",
        "\n",
        "#picking only the first 10 labels\n",
        "train = train[train['label'] < 10]\n",
        "# Setting the label and the feature columns\n",
        "y = train.loc[:,'label'].values\n",
        "x = train.loc[:,'pixel1':].values\n",
        "#view raw\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z4Z7MqIG_wu"
      },
      "source": [
        "\n",
        "def plot_2d(component1, component2):\n",
        "    \n",
        "    fig = go.Figure(data=go.Scatter(\n",
        "        x = component1,\n",
        "        y = component2,\n",
        "        mode='markers',\n",
        "        marker=dict(\n",
        "            size=20,\n",
        "            color=y, #set color equal to a variable\n",
        "            colorscale='Rainbow', # one of plotly colorscales\n",
        "            showscale=True,\n",
        "            line_width=1\n",
        "        )\n",
        "    ))\n",
        "    fig.update_layout(margin=dict( l=100,r=100,b=100,t=100),width=2000,height=1200)                 \n",
        "    fig.layout.template = 'plotly_dark'\n",
        "    \n",
        "    fig.show()\n",
        "\n",
        "\n",
        "def plot_3d(component1,component2,component3):\n",
        "fig = go.Figure(data=[go.Scatter3d(\n",
        "        x=component1,\n",
        "        y=component2,\n",
        "        z=component3,\n",
        "        mode='markers',\n",
        "        marker=dict(\n",
        "            size=10,\n",
        "            color=y,                # set color to an array/list of desired values\n",
        "            colorscale='Rainbow',   # choose a colorscale\n",
        "            opacity=1,\n",
        "            line_width=1\n",
        "        )\n",
        "    )])\n",
        "# tight layout\n",
        "    fig.update_layout(margin=dict(l=50,r=50,b=50,t=50),width=1800,height=1000)\n",
        "    fig.layout.template = 'plotly_dark'\n",
        "    \n",
        "    fig.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-mTEwQ8HLVp"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "## Standardizing the data\n",
        "x = StandardScaler().fit_transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiVCWjZeIH3H"
      },
      "source": [
        "start = time.time()\n",
        "pca = PCA(n_components=3)\n",
        "principalComponents = pca.fit_transform(x)\n",
        "print('Duration: {} seconds'.format(time.time() - start))\n",
        "principal = pd.DataFrame(data = principalComponents\n",
        "             , columns = ['principal component 1', 'principal component 2','principal component 3'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vURKmRoIK7W"
      },
      "source": [
        "plot_2d(principalComponents[:, 0],principalComponents[:, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryxt6JL3INSM"
      },
      "source": [
        "plot_3d(principalComponents[:, 0],principalComponents[:, 1],principalComponents[:, 2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOnlcAYOIP48"
      },
      "source": [
        "## TSNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTLCMdtVISKd"
      },
      "source": [
        "start = time.time()\n",
        "pca_50 = PCA(n_components=50)\n",
        "pca_result_50 = pca_50.fit_transform(x)\n",
        "tsne = TSNE(random_state = 42, n_components=3,verbose=0, perplexity=40, n_iter=400).fit_transform(pca_result_50)\n",
        "print('Duration: {} seconds'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gavQW9lAIWHg"
      },
      "source": [
        "plot_2d(tsne[:, 0],tsne[:, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B5mi3g8IY7D"
      },
      "source": [
        "plot_3d(tsne[:, 0],tsne[:, 1],tsne[:, 2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG-gOZ3LIa62"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfgjKdvxIcAj"
      },
      "source": [
        "## UMAP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IebV1DB1IdAG"
      },
      "source": [
        "start = time.time()\n",
        "reducer = umap.UMAP(random_state=42,n_components=3)\n",
        "embedding = reducer.fit_transform(x)\n",
        "print('Duration: {} seconds'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jawtSlAXIg2e"
      },
      "source": [
        "plot_2d(reducer.embedding_[:, 0],reducer.embedding_[:, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2hqrtBFIlIQ"
      },
      "source": [
        "plot_3d(reducer.embedding_[:, 0],reducer.embedding_[:, 1],reducer.embedding_[:, 2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U12TeCJKIvt7"
      },
      "source": [
        "Summary\n",
        "\n",
        "We have explored four dimensionality reduction techniques for data visualization : (PCA, t-SNE, UMAP, LDA)and tried to use them to visualize a high-dimensional dataset in 2d and 3d plots.\n",
        "\n",
        "Based on this Tutorial for this particular use case we can say that:\n",
        "\n",
        "    PCA did not work quite well in categorizing the different signs (10). However, instead of arbitrarily choosing the number dimensions to 3, it is much better to choose the number of dimensions that add up to a sufficiently large proportion of variance, but since this is data visualization problem that was the most reasonable thing to do.\n",
        "    TSNE managed to do better work on separating the clusters, the visualization in 2d and 3d was better than PCA definitely. However, it took a very long time to compute its embeddings.t-SNE doesn’t have major use outside visualisation.\n",
        "    UMAP turned out to be the most effective manifold learning in terms of displaying the different clusters with clear separations, However not good enough clusters for multi-class pattern classification.\n",
        "    LDA outperformed all the above techniques Excellent computation time (second fastest) as well as proving the well-separated clusters we were expecting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELc2qG0SIwY6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}