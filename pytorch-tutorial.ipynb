{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f44e60288ced4de6b853409363d25093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_284e38c05e604cdbb335a17ee344bf1e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_32e1eeaf13334ddc9448bb62fa1630d6",
              "IPY_MODEL_013f58a977314603a04b32187c636dd4"
            ]
          }
        },
        "284e38c05e604cdbb335a17ee344bf1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32e1eeaf13334ddc9448bb62fa1630d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_451555cf00334438a032514af9133b25",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35103115ec914ee9b6acdd5b3a2c8c59"
          }
        },
        "013f58a977314603a04b32187c636dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3f7a61cc280a4655a1c7b13562c68251",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 23786739.21it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2fabf676d1164212b31887c698a8d75d"
          }
        },
        "451555cf00334438a032514af9133b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35103115ec914ee9b6acdd5b3a2c8c59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f7a61cc280a4655a1c7b13562c68251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2fabf676d1164212b31887c698a8d75d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38745e78bffe45bfad98317490371a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4d4b48479e134f36b80caf88b2c3c391",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2f8142585722405abaa4175e674d2525",
              "IPY_MODEL_e23c546f7f2b432fa2a7907eb2bb40b0"
            ]
          }
        },
        "4d4b48479e134f36b80caf88b2c3c391": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f8142585722405abaa4175e674d2525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d4de129f34154f51a86d97bca4b7e8d6",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0beefacf709d4adbb78d3a6fc6f17ebe"
          }
        },
        "e23c546f7f2b432fa2a7907eb2bb40b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2413aed024434e44aad4431bc43628a3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 76.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c188555ccc2548908b8b44b46c9c2506"
          }
        },
        "d4de129f34154f51a86d97bca4b7e8d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0beefacf709d4adbb78d3a6fc6f17ebe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2413aed024434e44aad4431bc43628a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c188555ccc2548908b8b44b46c9c2506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xhxuciedu/CS284A/blob/master/pytorch-tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FKQCFzXDnGH"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import sys\n",
        "import torch \n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw_f9layCouO"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "def set_default(figsize=(8, 5), dpi=100):\n",
        "    plt.style.use(['dark_background', 'bmh'])\n",
        "    plt.rc('axes', facecolor='k')\n",
        "    plt.rc('figure', facecolor='k')\n",
        "    plt.rc('figure', figsize=figsize, dpi=dpi)\n",
        "\n",
        "set_default()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_w92gMaP6N1"
      },
      "source": [
        "### Check Package Versions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYr2YRtWPkel",
        "outputId": "619c70ca-cd53-4f50-81c7-c6b4a0637b30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('__Python VERSION:', sys.version)\n",
        "print('__PyTorch VERSION:', torch.__version__)\n",
        "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
        "print('__Number CUDA Devices:', torch.cuda.device_count())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__Python VERSION: 3.6.9 (default, Oct  8 2020, 12:12:24) \n",
            "[GCC 8.4.0]\n",
            "__PyTorch VERSION: 1.7.0+cu101\n",
            "__CUDNN VERSION: 7603\n",
            "__Number CUDA Devices: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Eq_6EZ0QM23"
      },
      "source": [
        "### PyTorch\n",
        "What is PyTorch?\n",
        "\n",
        "It’s a Python based scientific computing package targeted at two sets of audiences:\n",
        "\n",
        "* A replacement for numpy to use the power of GPUs\n",
        "* a deep learning research platform that provides maximum flexibility and speed\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSa2TTQfQ3nS"
      },
      "source": [
        "### Tensors\n",
        "\n",
        "Tensors are similar to numpy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n",
        "\n",
        "\n",
        "Construct a 5x3 matrix, uninitialized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTW9C9zVRLWy",
        "outputId": "f4aadbd0-7e67-451a-8e46-1a2706e9c7eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.Tensor(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[5.8067e-36, 0.0000e+00, 3.7835e-44],\n",
            "        [0.0000e+00,        nan, 0.0000e+00],\n",
            "        [1.3733e-14, 6.4069e+02, 4.3066e+21],\n",
            "        [1.1824e+22, 4.3066e+21, 6.3828e+28],\n",
            "        [3.8016e-39, 0.0000e+00, 0.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i74pPBySRRDZ",
        "outputId": "370dbff5-467f-4707-e57c-688fbc2cec53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get its size\n",
        "y = torch.rand(5, 3)\n",
        "print(x + y)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[6.7897e-01, 2.4498e-01, 3.4984e-01],\n",
            "        [9.6603e-01,        nan, 9.7634e-01],\n",
            "        [3.4864e-01, 6.4157e+02, 4.3066e+21],\n",
            "        [1.1824e+22, 4.3066e+21, 6.3828e+28],\n",
            "        [6.7610e-01, 6.2939e-01, 9.4387e-01]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0xeSB-3Rd1L",
        "outputId": "93902306-1fc7-44c0-e9a6-6c628792b007",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Addition: in-place\n",
        "y.add_(x)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6.7897e-01, 2.4498e-01, 3.4984e-01],\n",
              "        [9.6603e-01,        nan, 9.7634e-01],\n",
              "        [3.4864e-01, 6.4157e+02, 4.3066e+21],\n",
              "        [1.1824e+22, 4.3066e+21, 6.3828e+28],\n",
              "        [6.7610e-01, 6.2939e-01, 9.4387e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QagJi5H9YT_M"
      },
      "source": [
        "### Create tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF881O3lYfwc"
      },
      "source": [
        "# random\n",
        "v = torch.rand(2, 3)            # Initialize with random number (uniform distribution)\n",
        "v = torch.randn(2, 3)           # With normal distribution (SD=1, mean=0)\n",
        "v = torch.randperm(4)   \n",
        "\n",
        "# ones\n",
        "eye = torch.eye(3)              # Create an identity 3x3 tensor\n",
        "v = torch.ones(10)              # A tensor of size 10 containing all ones\n",
        "v = torch.ones(2, 1, 2, 1)      # Size 2x1x2x1\n",
        "v = torch.ones_like(eye)        # A tensor with same shape as eye. Fill it with 1.\n",
        "\n",
        "# zeros\n",
        "v = torch.zeros(10) \n",
        "\n",
        "# range of values\n",
        "v = torch.arange(5)             # similar to range(5) but creating a Tensor\n",
        "v = torch.arange(0, 5, step=1)  # Size 5. Similar to range(0, 5, 1)\n",
        "\n",
        "# linear or log scale\n",
        "v = torch.linspace(1, 10, steps=10) # Create a Tensor with 10 linear points for (1, 10) inclusively\n",
        "v = torch.logspace(start=-10, end=10, steps=5) # Size 5: 1.0e-10 1.0e-05 1.0e+00, 1.0e+05, 1.0e+10"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0_vX6QFbP9r"
      },
      "source": [
        "### Dot product, component-wide product, matrix multiplication, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbf5A2rTYonK"
      },
      "source": [
        "# Dot product of 2 tensors\n",
        "r = torch.dot(torch.Tensor([4, 2]), torch.Tensor([3, 1])) # 14"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-AZEEfEYosW",
        "outputId": "4aeb4587-ef07-4261-d524-7e91f66f4797",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# component-wise product\n",
        "torch.Tensor([4, 2])* torch.Tensor([3, 1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.,  2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnfFZpz4a0JG"
      },
      "source": [
        "# Matrix x Matrix\n",
        "# Size 2x4\n",
        "mat1 = torch.randn(2, 3)\n",
        "mat2 = torch.randn(3, 4)\n",
        "r = torch.mm(mat1, mat2)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fNQ8Aw-ahBH"
      },
      "source": [
        "# Batch Matrix x Matrix\n",
        "# Size 10x3x5\n",
        "batch1 = torch.randn(10, 3, 4)\n",
        "batch2 = torch.randn(10, 4, 5)\n",
        "r = torch.bmm(batch1, batch2)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zygHVhSba0eN"
      },
      "source": [
        "###Squeeze and unsqueeze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vylLWkFfaicW"
      },
      "source": [
        "t = torch.ones(2,1,2,1) # Size 2x1x2x1\n",
        "r = torch.squeeze(t)     # Size 2x2\n",
        "r = torch.squeeze(t, 1)  # Squeeze dimension 1: Size 2x2x1\n",
        "\n",
        "# Un-squeeze a dimension\n",
        "x = torch.Tensor([1, 2, 3])\n",
        "r = torch.unsqueeze(x, 0)       # Size: 1x3\n",
        "r = torch.unsqueeze(x, 1)       # Size: 3x1"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6gEsNF3a-26"
      },
      "source": [
        "### Transpose\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwCePtvPa_hO",
        "outputId": "e6b090fa-5061-417e-cc8b-8a5c50a5c343",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Transpose dim 0 and 1\n",
        "v = torch.randn(3,2)\n",
        "r = torch.transpose(v, 0, 1)\n",
        "print(r.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6wj7JQJRna5"
      },
      "source": [
        "### Numpy Bridge\n",
        "Converting a torch Tensor to a numpy array and vice versa is a breeze.\n",
        "\n",
        "The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the other.\n",
        "\n",
        "Converting torch Tensor to numpy Array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-V3P-KeOdFY"
      },
      "source": [
        "# Create a numpy array.\n",
        "x = np.array([[1, 2], [3, 4]])\n",
        "\n",
        "# Convert the numpy array to a torch tensor.\n",
        "y = torch.from_numpy(x)\n",
        "\n",
        "# Convert the torch tensor to a numpy array.\n",
        "z = y.numpy()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrxFA9zrOhcw"
      },
      "source": [
        "# Conversion\n",
        "a = np.array([1, 2, 3])\n",
        "v = torch.from_numpy(a)         # Convert a numpy array to a Tensor\n",
        "\n",
        "b = v.numpy()                   # Tensor to numpy\n",
        "b[1] = -1                       # Numpy and Tensor share the same memory\n",
        "assert(a[1] == b[1])            # Change Numpy will also change the Tensor"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkrFAPSzYDLa"
      },
      "source": [
        "### Reshape tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVJAK82AYB78",
        "outputId": "23aa0612-47f4-452d-ff66-905656a4390b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### Tensor resizing\n",
        "x = torch.randn(2, 3)            # Size 2x3\n",
        "y = x.view(6)                    # Resize x to size 6\n",
        "z = x.view(-1, 2)                # Size 3x2\n",
        "print(y.shape, z.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6]) torch.Size([3, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfoEcojSYTra"
      },
      "source": [
        ""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJnuUJgeSH5S"
      },
      "source": [
        "###CUDA Tensors\n",
        "\n",
        "All the Tensors on the CPU except a CharTensor support converting to NumPy and back.\n",
        "\n",
        "\n",
        "Tensors can be moved onto GPU using the .cuda function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPUVPxqbSP_8"
      },
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "\n",
        "x = torch.rand(3,2)\n",
        "y = torch.rand(3,2)\n",
        "if torch.cuda.is_available():\n",
        "    x = x.cuda()\n",
        "    y = y.cuda()\n",
        "    x + y"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUYQkqCUSiRT",
        "outputId": "c7f9ea9a-c263-448e-dc1a-4850718d953b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8200, 0.7632],\n",
              "        [0.2346, 0.3053],\n",
              "        [0.6123, 0.0609]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N20kEqktSQKm",
        "outputId": "5cdadc8e-000c-4746-f9fe-261e630e8053",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2591, 0.3079],\n",
              "        [0.3886, 0.8800],\n",
              "        [0.2207, 0.0953]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mS3kiy9UNoR"
      },
      "source": [
        "## Autograd: automatic differentiation\n",
        "\n",
        "Central to all neural networks in PyTorch is autograd, a core torch package for automatic differentiation. \n",
        "\n",
        "\n",
        "The autograd package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different.\n",
        "\n",
        "Let us see this in more simple terms with some examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmxgzX_6U4rn"
      },
      "source": [
        "# create an variable\n",
        "x = torch.ones((2,2), requires_grad=True)\n",
        "\n",
        "# Do an operation of variable:\n",
        "y = x + 2\n",
        "\n",
        "# Do more operations on y\n",
        "z = y * y * 3\n",
        "out = z.mean()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdNxo2rxU4zr"
      },
      "source": [
        "# Gradients\n",
        "# ---------\n",
        "# let's backprop now\n",
        "# ``out.backward()`` is equivalent to doing ``out.backward(torch.Tensor([1.0]))``\n",
        "out.backward()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNK-RRBmU43f",
        "outputId": "8171eb0f-69ae-48a9-a99e-6fb89a0a09ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "###############################################################\n",
        "# print gradients d(out)/dx\n",
        "#\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUDiTPCeWGlU"
      },
      "source": [
        "You should have got a matrix of ``4.5``. Let’s call the ``out`` *Variable* $o$.\n",
        "We have that: $o = \\frac{1}{4}\\sum_i z_i$, \n",
        "$z_i = 3(x_i+2)^2$ and $z_i\\bigr\\rvert_{x_i=1} = 27$\n",
        "\n",
        "Therefore,\n",
        "$$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$$ hence\n",
        "$$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKL_ex-DWs_L",
        "outputId": "719beb18-fca4-4f96-bc50-57c45960985d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# You can do many crazy things with autograd!\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  786.5998, -1256.1101,  -949.4398], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmSVgbJNWyqu",
        "outputId": "413908d9-4cc0-4f49-c0d1-9e15da19f7ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
        "y.backward(gradients)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ5oVt1kFv6N"
      },
      "source": [
        "### Basic autograd example 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx-5ce4DE2y-"
      },
      "source": [
        "# Create tensors.\n",
        "x = torch.tensor(1., requires_grad=True)\n",
        "w = torch.tensor(2., requires_grad=True)\n",
        "b = torch.tensor(3., requires_grad=True)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcy6p4nSE5Yt"
      },
      "source": [
        "# Build a computational graph.\n",
        "y = w * x + b    # y = 2 * x + 3"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzfF4EDBGyJB"
      },
      "source": [
        "# Compute gradients.\n",
        "y.backward()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3hIZDh1GrJn",
        "outputId": "3aef6fa0-20fb-488d-d495-99bfbf17c1f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print out the gradients.\n",
        "print(x.grad)    # x.grad = 2 \n",
        "print(w.grad)    # w.grad = 1 \n",
        "print(b.grad)    # b.grad = 1 "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.)\n",
            "tensor(1.)\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiS-D364E6JC",
        "outputId": "48f44f50-ea0c-443d-e3f2-5300c9bd94db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y.detach().numpy()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(5., dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahapqf3VF8Fn"
      },
      "source": [
        "### Basic autograd example 2  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgah0xn0GCxA",
        "outputId": "5fe7840c-eea7-4742-81f9-280cb2867bde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create tensors of shape (10, 3) and (10, 2).\n",
        "x = torch.randn(10, 3)\n",
        "y = torch.randn(10, 2)\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 3]) torch.Size([10, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiQkdoJXGLeJ",
        "outputId": "ba37e615-27ea-4a5b-9465-900075732da2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Build a fully connected layer.\n",
        "linear = nn.Linear(3, 2)\n",
        "print ('w: ', linear.weight)\n",
        "print ('b: ', linear.bias)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w:  Parameter containing:\n",
            "tensor([[ 1.3139e-04,  3.5169e-01,  1.7677e-01],\n",
            "        [-2.7495e-01,  3.2226e-01,  1.1678e-01]], requires_grad=True)\n",
            "b:  Parameter containing:\n",
            "tensor([-0.3082,  0.0621], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvOuGobUG_c4",
        "outputId": "eb6275cb-b1b8-4367-c4c4-53c1a5ce9b3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "loss = torch.sum((linear(x)-y)**2)/y.shape[0]\n",
        "print('loss: ', loss.data.numpy())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss:  3.1104836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jg-jZqxIswR"
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIJ9YkofIszl",
        "outputId": "70691a05-35b8-47fb-af54-c3335cb7950b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('w grad: ', linear.weight.grad)\n",
        "print('b grad: ', linear.bias.grad)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w grad:  tensor([[ 0.6055,  0.2772, -0.3877],\n",
            "        [-0.3933,  1.1693,  1.8184]])\n",
            "b grad:  tensor([-0.1714,  0.3147])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPtT7MCXJJsj",
        "outputId": "f7b8482e-52a8-4f4d-c830-d3e3b4f276f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check grad\n",
        "print('w grad:', (linear(x)-y).transpose(0,1).mm(x)/y.shape[0]*2)\n",
        "print('b grad:', 2*torch.mean(linear(x)-y, dim=0))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w grad: tensor([[ 0.6055,  0.2772, -0.3877],\n",
            "        [-0.3933,  1.1693,  1.8184]], grad_fn=<MulBackward0>)\n",
            "b grad: tensor([-0.1714,  0.3147], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy7Cv9ugMN0K"
      },
      "source": [
        "###. Basic autograd example 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hon-LU88MN6L"
      },
      "source": [
        "# Create tensors of shape (10, 3) and (10, 2).\n",
        "x = torch.randn(10, 3)\n",
        "y = torch.randn(10, 2)\n",
        "linear = nn.Linear(3, 2)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltmT6QfoFMal",
        "outputId": "7465219a-5fba-409b-b782-ce7c6ebb6f81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Build loss function and optimizer.\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
        "\n",
        "# Forward pass.\n",
        "pred = linear(x)\n",
        "\n",
        "# Compute loss.\n",
        "loss = criterion(pred, y)\n",
        "print('loss: ', loss.item())\n",
        "\n",
        "# Backward pass.\n",
        "loss.backward()\n",
        "\n",
        "# Print out the gradients.\n",
        "print ('dL/dw: ', linear.weight.grad) \n",
        "print ('dL/db: ', linear.bias.grad)\n",
        "\n",
        "# 1-step gradient descent.\n",
        "optimizer.step()\n",
        "\n",
        "# You can also perform gradient descent at the low level.\n",
        "# linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n",
        "# linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n",
        "\n",
        "# Print out the loss after 1-step gradient descent.\n",
        "pred = linear(x)\n",
        "loss = criterion(pred, y)\n",
        "print('loss after 1 step optimization: ', loss.item())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss:  1.4289391040802002\n",
            "dL/dw:  tensor([[ 0.4425,  0.4435, -0.2337],\n",
            "        [ 0.6657,  0.2639, -0.1948]])\n",
            "dL/db:  tensor([-0.5005, -0.2522])\n",
            "loss after 1 step optimization:  1.4158974885940552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO2btHYRjJ6D"
      },
      "source": [
        "## Input pipeline, Data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC-xoV6kPmlm",
        "outputId": "7b0d0d90-bffa-4361-e832-19339c3b3907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119,
          "referenced_widgets": [
            "f44e60288ced4de6b853409363d25093",
            "284e38c05e604cdbb335a17ee344bf1e",
            "32e1eeaf13334ddc9448bb62fa1630d6",
            "013f58a977314603a04b32187c636dd4",
            "451555cf00334438a032514af9133b25",
            "35103115ec914ee9b6acdd5b3a2c8c59",
            "3f7a61cc280a4655a1c7b13562c68251",
            "2fabf676d1164212b31887c698a8d75d"
          ]
        }
      },
      "source": [
        "# Download and construct CIFAR-10 dataset.\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                             train=True, \n",
        "                                             transform=transforms.ToTensor(),\n",
        "                                             download=True)\n",
        "\n",
        "# Fetch one data pair (read data from disk).\n",
        "image, label = train_dataset[0]\n",
        "print (image.size())\n",
        "print (label)\n",
        "\n",
        "# Data loader (this provides queues and threads in a very simple way).\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=64, \n",
        "                                           shuffle=True)\n",
        "\n",
        "# When iteration starts, queue and thread start to load data from files.\n",
        "data_iter = iter(train_loader)\n",
        "\n",
        "# Mini-batch images and labels.\n",
        "images, labels = data_iter.next()\n",
        "\n",
        "# Actual usage of the data loader is as below.\n",
        "for images, labels in train_loader:\n",
        "    # Training code should be written here.\n",
        "    pass"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../../data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f44e60288ced4de6b853409363d25093",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../../data/cifar-10-python.tar.gz to ../../data/\n",
            "torch.Size([3, 32, 32])\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI16kN0tjnRl"
      },
      "source": [
        "### Input pipeline for custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLfA6_yGjlwF"
      },
      "source": [
        "# # ================================================================== #\n",
        "# #                  Input pipeline for custom dataset                 #\n",
        "# # ================================================================== #\n",
        "\n",
        "# # You should build your custom dataset as below.\n",
        "# class CustomDataset(torch.utils.data.Dataset):\n",
        "#     def __init__(self):\n",
        "#         # TODO\n",
        "#         # 1. Initialize file paths or a list of file names. \n",
        "#         pass\n",
        "#     def __getitem__(self, index):\n",
        "#         # TODO\n",
        "#         # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
        "#         # 2. Preprocess the data (e.g. torchvision.Transform).\n",
        "#         # 3. Return a data pair (e.g. image and label).\n",
        "#         pass\n",
        "#     def __len__(self):\n",
        "#         # You should change 0 to the total size of your dataset.\n",
        "#         return 0 \n",
        "\n",
        "# # You can then use the prebuilt data loader. \n",
        "# custom_dataset = CustomDataset()\n",
        "# train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n",
        "#                                            batch_size=64, \n",
        "#                                            shuffle=True)\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olrd4PlTjgv7"
      },
      "source": [
        "### Pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRsDNLcKjfGz",
        "outputId": "42af1b31-1f1b-4b0c-8d4e-c9a90e7582d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "38745e78bffe45bfad98317490371a96",
            "4d4b48479e134f36b80caf88b2c3c391",
            "2f8142585722405abaa4175e674d2525",
            "e23c546f7f2b432fa2a7907eb2bb40b0",
            "d4de129f34154f51a86d97bca4b7e8d6",
            "0beefacf709d4adbb78d3a6fc6f17ebe",
            "2413aed024434e44aad4431bc43628a3",
            "c188555ccc2548908b8b44b46c9c2506"
          ]
        }
      },
      "source": [
        "# ================================================================== #\n",
        "#                           Pretrained model                         #\n",
        "# ================================================================== #\n",
        "\n",
        "# Download and load the pretrained ResNet-18.\n",
        "resnet = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# If you want to finetune only the top layer of the model, set as below.\n",
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the top layer for finetuning.\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, 100)  # 100 is an example.\n",
        "\n",
        "# Forward pass.\n",
        "images = torch.randn(64, 3, 224, 224)\n",
        "outputs = resnet(images)\n",
        "print (outputs.size())     # (64, 100)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38745e78bffe45bfad98317490371a96",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "torch.Size([64, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VbbrBlBjY6P"
      },
      "source": [
        "### Save and load the model    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfYBD7T_jW6f",
        "outputId": "ac1250c9-52b7-4434-9888-5c9e2417f41f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Save and load the entire model.\n",
        "torch.save(resnet, 'model.ckpt')\n",
        "model = torch.load('model.ckpt')\n",
        "\n",
        "# Save and load only the model parameters (recommended).\n",
        "torch.save(resnet.state_dict(), 'params.ckpt')\n",
        "resnet.load_state_dict(torch.load('params.ckpt'))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx1gFIdtjdcE"
      },
      "source": [
        ""
      ],
      "execution_count": 54,
      "outputs": []
    }
  ]
}